{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Torch and Opacus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1603974750434,
     "user": {
      "displayName": "M. M.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhyyTTQ0So37s4ik4Tk9Pfpi6S1BXAqGjSafRcO=s64",
      "userId": "11054559934326118576"
     },
     "user_tz": 0
    },
    "id": "BsTiBPNuhU2p"
   },
   "outputs": [],
   "source": [
    "!pip install torchcsprng==0.1.2+cu101 torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install opacus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Connect GDrive to this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1959,
     "status": "ok",
     "timestamp": 1603974751910,
     "user": {
      "displayName": "M. M.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhyyTTQ0So37s4ik4Tk9Pfpi6S1BXAqGjSafRcO=s64",
      "userId": "11054559934326118576"
     },
     "user_tz": 0
    },
    "id": "1zRko5ZshZsn",
    "outputId": "572c0c54-e29c-44c0-ae4f-eca607a64ac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/', force_remount= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1956,
     "status": "ok",
     "timestamp": 1603974751911,
     "user": {
      "displayName": "M. M.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhyyTTQ0So37s4ik4Tk9Pfpi6S1BXAqGjSafRcO=s64",
      "userId": "11054559934326118576"
     },
     "user_tz": 0
    },
    "id": "V3aZGxDCheG0",
    "outputId": "2c6a3104-eac2-486c-9bfe-7d528e4e498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/Opacus\n"
     ]
    }
   ],
   "source": [
    "cd gdrive/My\\ Drive/Opacus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import the \"src\" Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1951,
     "status": "ok",
     "timestamp": 1603974751911,
     "user": {
      "displayName": "M. M.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhyyTTQ0So37s4ik4Tk9Pfpi6S1BXAqGjSafRcO=s64",
      "userId": "11054559934326118576"
     },
     "user_tz": 0
    },
    "id": "j7KxxOIchgeW"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src/\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The Main Function to Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2899,
     "status": "ok",
     "timestamp": 1603974752862,
     "user": {
      "displayName": "M. M.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhyyTTQ0So37s4ik4Tk9Pfpi6S1BXAqGjSafRcO=s64",
      "userId": "11054559934326118576"
     },
     "user_tz": 0
    },
    "id": "Hx-Lonk7hjtF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from options import args_parser\n",
    "from update_s4 import LocalUpdate\n",
    "from utils import test_inference\n",
    "from models import CNNMnistRelu, CNNMnistTanh\n",
    "from models import CNNFashion_MnistRelu, CNNFashion_MnistTanh\n",
    "from models import CNNCifar10Relu, CNNCifar10Tanh\n",
    "from utils import average_weights, exp_details\n",
    "from datasets import get_dataset\n",
    "from torchvision import models\n",
    "from logging_results import logging\n",
    "\n",
    "from opacus.dp_model_inspector import DPModelInspector\n",
    "from opacus.utils import module_modification\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    \n",
    "    ############# Common ###################\n",
    "    # args = args_parser()    \n",
    "    if args.gpu:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "    device = 'cuda' if args.gpu else 'cpu'    \n",
    "    \n",
    "    # load dataset and user groups\n",
    "    train_dataset, test_dataset, user_groups = get_dataset(args)\n",
    "\n",
    "    \n",
    "    # BUILD MODEL\n",
    "    if args.model == 'cnn':\n",
    "        # Convolutional neural netork\n",
    "        if args.dataset == 'mnist':\n",
    "            if args.activation == 'relu':\n",
    "                global_model = CNNMnistRelu()\n",
    "            elif args.activation == 'tanh':\n",
    "                global_model = CNNMnistTanh()\n",
    "            global_model.to(device)\n",
    "            summary(global_model, input_size=(1, 28, 28), device=device)\n",
    "        elif args.dataset == 'fmnist':\n",
    "            if args.activation == 'relu':\n",
    "                global_model = CNNFashion_MnistRelu()\n",
    "            elif args.activation == 'tanh':\n",
    "                global_model = CNNFashion_MnistTanh()\n",
    "            global_model.to(device)\n",
    "            summary(global_model, input_size=(1, 28, 28), device=device)\n",
    "        elif args.dataset == 'cifar10':\n",
    "            # global_model = models.resnet18(num_classes=10)  \n",
    "            if args.activation == 'relu':\n",
    "                global_model = CNNCifar10Relu()\n",
    "            elif args.activation == 'tanh':\n",
    "                global_model = CNNCifar10Tanh()\n",
    "            global_model.to(device)\n",
    "            summary(global_model, input_size=(3, 32, 32), device=device)\n",
    "        elif args.dataset == 'dr':    \n",
    "            global_model = models.squeezenet1_1(pretrained=True)           \n",
    "            global_model.classifier[1] = nn.Conv2d(512, 5, kernel_size=(1,1), stride=(1,1))\n",
    "            global_model.num_classes = 5\n",
    "            global_model.to(device)\n",
    "            summary(global_model, input_size=(3, 224, 224), device=device)\n",
    "    else:\n",
    "        exit('Error: unrecognized model')\n",
    "    ############# Common ###################\n",
    "\n",
    "    ######### DP Model Compatibility #######\n",
    "    if args.withDP:\n",
    "        try:\n",
    "            inspector = DPModelInspector()\n",
    "            inspector.validate(global_model)\n",
    "            print(\"Model's already Valid!\\n\")\n",
    "        except:\n",
    "            global_model = module_modification.convert_batchnorm_modules(global_model)\n",
    "            inspector = DPModelInspector()\n",
    "            print(f\"Is the model valid? {inspector.validate(global_model)}\")\n",
    "            print(\"Model is convereted to be Valid!\\n\")        \n",
    "    ######### DP Model Compatibility #######\n",
    "\n",
    "    \n",
    "\n",
    "    ######### Local Models and Optimizers #############\n",
    "    local_models = []\n",
    "    local_optimizers = []\n",
    "    local_privacy_engine = []\n",
    "\n",
    "    for u in range(args.num_users):\n",
    "        local_models.append(copy.deepcopy(global_model))\n",
    "\n",
    "        if args.optimizer == 'sgd':\n",
    "            optimizer = torch.optim.SGD(local_models[u].parameters(), lr=args.lr, \n",
    "                                        momentum=args.momentum)        \n",
    "        elif args.optimizer == 'adam':\n",
    "            optimizer = torch.optim.Adam(local_models[u].parameters(), lr=args.lr)             \n",
    "\n",
    "        if args.withDP:\n",
    "          # This part is buggy intentionally. It makes privacy engine avoid giving error with vhp.\n",
    "            \n",
    "            privacy_engine = PrivacyEngine(\n",
    "                local_models[u],\n",
    "                batch_size = int(len(train_dataset)*args.sampling_prob), \n",
    "                sample_size = len(train_dataset), \n",
    "                alphas=[1 + x / 10.0 for x in range(1, 100)] + list(range(12, 64)),\n",
    "                noise_multiplier = args.noise_multiplier/np.sqrt(args.num_users),\n",
    "                max_grad_norm =  args.max_grad_norm,\n",
    "            )\n",
    "\n",
    "            privacy_engine.attach(optimizer)            \n",
    "            local_privacy_engine.append(privacy_engine)\n",
    "\n",
    "        local_optimizers.append(optimizer)\n",
    "\n",
    "\n",
    "    if args.optimizer == 'sgd':\n",
    "        g_optimizer = torch.optim.SGD(global_model.parameters(), lr=args.lr, \n",
    "                                    momentum=args.momentum)        \n",
    "    elif args.optimizer == 'adam':\n",
    "        g_optimizer = torch.optim.Adam(global_model.parameters(), lr=args.lr)        \n",
    "    if args.withDP:\n",
    "        local_dataset_size = int(len(train_dataset)/args.num_users)\n",
    "        actual_train_ds_size = local_dataset_size*args.num_users\n",
    "        global_privacy_engine = PrivacyEngine(\n",
    "            global_model,\n",
    "            batch_size = int(actual_train_ds_size*args.sampling_prob),\n",
    "            sample_size = actual_train_ds_size,\n",
    "            alphas=[1 + x / 10.0 for x in range(1, 100)] + list(range(12, 64)),\n",
    "            noise_multiplier = args.noise_multiplier,\n",
    "            max_grad_norm =  args.max_grad_norm)  \n",
    "        global_privacy_engine.attach(g_optimizer)\n",
    "    ######## Local  Models and Optimizers #############\n",
    "\n",
    "    # Training\n",
    "    train_loss = []\n",
    "    test_log = []\n",
    "    epsilon_log = []\n",
    "    \n",
    "    print(\"Avg batch_size: \", int(actual_train_ds_size*args.sampling_prob))\n",
    "\n",
    "    for epoch in range(args.epochs):    \n",
    "        ## Sample the users ##        \n",
    "        idxs_users = np.random.choice(range(args.num_users),\n",
    "                                      max(int(args.frac * args.num_users), 1),\n",
    "                                      replace=False)\n",
    "        #####\n",
    "        local_weights, local_losses = [], []        \n",
    "        \n",
    "\n",
    "        for u in idxs_users:\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            local_model = LocalUpdate(args=args, dataset=train_dataset, \n",
    "                                      u_id=u, idxs=user_groups[u], \n",
    "                                      sampling_prob=args.sampling_prob,\n",
    "                                      optimizer = local_optimizers[u])\n",
    "\n",
    "            w, loss, local_optimizers[u] = local_model.update_weights(\n",
    "                                                    model=local_models[u],\n",
    "                                                    global_round=epoch)\n",
    "            local_weights.append(copy.deepcopy(w))\n",
    "            local_losses.append(copy.deepcopy(loss))\n",
    "            \n",
    "\n",
    "        # update global weights\n",
    "        global_weights = average_weights(local_weights)\n",
    "\n",
    "        # update global weights\n",
    "        global_model.load_state_dict(global_weights)\n",
    "        for u in range(args.num_users):\n",
    "            local_models[u].load_state_dict(global_weights)\n",
    "\n",
    "        if epoch !=0 and epoch%30==0:\n",
    "            torch.cuda.empty_cache()          \n",
    "            loss_avg = sum(local_losses) / len(local_losses)        \n",
    "            train_loss.append(loss_avg)\n",
    "\n",
    "            _acc, _loss = test_inference(args, global_model, test_dataset)        \n",
    "            test_log.append([_acc, _loss])  \n",
    "          \n",
    "            if args.withDP:\n",
    "                global_privacy_engine.steps = epoch+1\n",
    "                epsilons, _ = global_privacy_engine.get_privacy_spent(args.delta)                                        \n",
    "                epsilon_log.append([epsilons])\n",
    "            else:\n",
    "                epsilon_log = None\n",
    "\n",
    "            logging(args, epoch, train_loss, test_log, epsilon_log)\n",
    "            print(global_privacy_engine.steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. The Chosen Settings for the Experimt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6554847,
     "status": "ok",
     "timestamp": 1603981304812,
     "user": {
      "displayName": "M. M.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhyyTTQ0So37s4ik4Tk9Pfpi6S1BXAqGjSafRcO=s64",
      "userId": "11054559934326118576"
     },
     "user_tz": 0
    },
    "id": "-QWnIRCohldP",
    "outputId": "3bfc69f0-e631-432a-f7e6-812d2addad08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 111, 111]           1,792\n",
      "              ReLU-2         [-1, 64, 111, 111]               0\n",
      "         MaxPool2d-3           [-1, 64, 55, 55]               0\n",
      "            Conv2d-4           [-1, 16, 55, 55]           1,040\n",
      "              ReLU-5           [-1, 16, 55, 55]               0\n",
      "            Conv2d-6           [-1, 64, 55, 55]           1,088\n",
      "              ReLU-7           [-1, 64, 55, 55]               0\n",
      "            Conv2d-8           [-1, 64, 55, 55]           9,280\n",
      "              ReLU-9           [-1, 64, 55, 55]               0\n",
      "             Fire-10          [-1, 128, 55, 55]               0\n",
      "           Conv2d-11           [-1, 16, 55, 55]           2,064\n",
      "             ReLU-12           [-1, 16, 55, 55]               0\n",
      "           Conv2d-13           [-1, 64, 55, 55]           1,088\n",
      "             ReLU-14           [-1, 64, 55, 55]               0\n",
      "           Conv2d-15           [-1, 64, 55, 55]           9,280\n",
      "             ReLU-16           [-1, 64, 55, 55]               0\n",
      "             Fire-17          [-1, 128, 55, 55]               0\n",
      "        MaxPool2d-18          [-1, 128, 27, 27]               0\n",
      "           Conv2d-19           [-1, 32, 27, 27]           4,128\n",
      "             ReLU-20           [-1, 32, 27, 27]               0\n",
      "           Conv2d-21          [-1, 128, 27, 27]           4,224\n",
      "             ReLU-22          [-1, 128, 27, 27]               0\n",
      "           Conv2d-23          [-1, 128, 27, 27]          36,992\n",
      "             ReLU-24          [-1, 128, 27, 27]               0\n",
      "             Fire-25          [-1, 256, 27, 27]               0\n",
      "           Conv2d-26           [-1, 32, 27, 27]           8,224\n",
      "             ReLU-27           [-1, 32, 27, 27]               0\n",
      "           Conv2d-28          [-1, 128, 27, 27]           4,224\n",
      "             ReLU-29          [-1, 128, 27, 27]               0\n",
      "           Conv2d-30          [-1, 128, 27, 27]          36,992\n",
      "             ReLU-31          [-1, 128, 27, 27]               0\n",
      "             Fire-32          [-1, 256, 27, 27]               0\n",
      "        MaxPool2d-33          [-1, 256, 13, 13]               0\n",
      "           Conv2d-34           [-1, 48, 13, 13]          12,336\n",
      "             ReLU-35           [-1, 48, 13, 13]               0\n",
      "           Conv2d-36          [-1, 192, 13, 13]           9,408\n",
      "             ReLU-37          [-1, 192, 13, 13]               0\n",
      "           Conv2d-38          [-1, 192, 13, 13]          83,136\n",
      "             ReLU-39          [-1, 192, 13, 13]               0\n",
      "             Fire-40          [-1, 384, 13, 13]               0\n",
      "           Conv2d-41           [-1, 48, 13, 13]          18,480\n",
      "             ReLU-42           [-1, 48, 13, 13]               0\n",
      "           Conv2d-43          [-1, 192, 13, 13]           9,408\n",
      "             ReLU-44          [-1, 192, 13, 13]               0\n",
      "           Conv2d-45          [-1, 192, 13, 13]          83,136\n",
      "             ReLU-46          [-1, 192, 13, 13]               0\n",
      "             Fire-47          [-1, 384, 13, 13]               0\n",
      "           Conv2d-48           [-1, 64, 13, 13]          24,640\n",
      "             ReLU-49           [-1, 64, 13, 13]               0\n",
      "           Conv2d-50          [-1, 256, 13, 13]          16,640\n",
      "             ReLU-51          [-1, 256, 13, 13]               0\n",
      "           Conv2d-52          [-1, 256, 13, 13]         147,712\n",
      "             ReLU-53          [-1, 256, 13, 13]               0\n",
      "             Fire-54          [-1, 512, 13, 13]               0\n",
      "           Conv2d-55           [-1, 64, 13, 13]          32,832\n",
      "             ReLU-56           [-1, 64, 13, 13]               0\n",
      "           Conv2d-57          [-1, 256, 13, 13]          16,640\n",
      "             ReLU-58          [-1, 256, 13, 13]               0\n",
      "           Conv2d-59          [-1, 256, 13, 13]         147,712\n",
      "             ReLU-60          [-1, 256, 13, 13]               0\n",
      "             Fire-61          [-1, 512, 13, 13]               0\n",
      "          Dropout-62          [-1, 512, 13, 13]               0\n",
      "           Conv2d-63            [-1, 5, 13, 13]           2,565\n",
      "             ReLU-64            [-1, 5, 13, 13]               0\n",
      "AdaptiveAvgPool2d-65              [-1, 5, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 725,061\n",
      "Trainable params: 725,061\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 51.19\n",
      "Params size (MB): 2.77\n",
      "Estimated Total Size (MB): 54.53\n",
      "----------------------------------------------------------------\n",
      "Model's already Valid!\n",
      "\n",
      "Avg batch_size:  100\n",
      "\n",
      "Epoch: 31\n",
      "Average train loss: 0.8680304259061813\n",
      "Test Accuracy: 66.48%\n",
      "epsilons: max 1.60,  mean 1.60, std 0.00\n",
      "31\n",
      "\n",
      "Epoch: 61\n",
      "Average train loss: 1.2338550209999084\n",
      "Test Accuracy: 66.35%\n",
      "epsilons: max 1.88,  mean 1.88, std 0.00\n",
      "61\n",
      "\n",
      "Epoch: 91\n",
      "Average train loss: 0.7700409732758999\n",
      "Test Accuracy: 69.22%\n",
      "epsilons: max 2.12,  mean 2.12, std 0.00\n",
      "91\n",
      "\n",
      "Epoch: 121\n",
      "Average train loss: 1.3446020433679222\n",
      "Test Accuracy: 69.22%\n",
      "epsilons: max 2.34,  mean 2.34, std 0.00\n",
      "121\n",
      "\n",
      "Epoch: 151\n",
      "Average train loss: 1.0365302547812463\n",
      "Test Accuracy: 69.49%\n",
      "epsilons: max 2.54,  mean 2.54, std 0.00\n",
      "151\n",
      "\n",
      "Epoch: 181\n",
      "Average train loss: 1.4126135781407356\n",
      "Test Accuracy: 70.18%\n",
      "epsilons: max 2.72,  mean 2.72, std 0.00\n",
      "181\n",
      "\n",
      "Epoch: 211\n",
      "Average train loss: 1.0700196724385023\n",
      "Test Accuracy: 70.04%\n",
      "epsilons: max 2.90,  mean 2.90, std 0.00\n",
      "211\n",
      "\n",
      "Epoch: 241\n",
      "Average train loss: 1.4402373015880585\n",
      "Test Accuracy: 71.00%\n",
      "epsilons: max 3.06,  mean 3.06, std 0.00\n",
      "241\n",
      "\n",
      "Epoch: 271\n",
      "Average train loss: 1.1214185684919358\n",
      "Test Accuracy: 71.27%\n",
      "epsilons: max 3.22,  mean 3.22, std 0.00\n",
      "271\n",
      "\n",
      "Epoch: 301\n",
      "Average train loss: 1.675106292963028\n",
      "Test Accuracy: 71.82%\n",
      "epsilons: max 3.37,  mean 3.37, std 0.00\n",
      "301\n",
      "\n",
      "Epoch: 331\n",
      "Average train loss: 1.6015321703249357\n",
      "Test Accuracy: 71.96%\n",
      "epsilons: max 3.52,  mean 3.52, std 0.00\n",
      "331\n",
      "\n",
      "Epoch: 361\n",
      "Average train loss: 1.449118322134018\n",
      "Test Accuracy: 71.41%\n",
      "epsilons: max 3.66,  mean 3.66, std 0.00\n",
      "361\n",
      "\n",
      "Epoch: 391\n",
      "Average train loss: 1.4826807975769043\n",
      "Test Accuracy: 71.96%\n",
      "epsilons: max 3.79,  mean 3.79, std 0.00\n",
      "391\n",
      "\n",
      "Epoch: 421\n",
      "Average train loss: 0.9254130482673645\n",
      "Test Accuracy: 71.68%\n",
      "epsilons: max 3.93,  mean 3.93, std 0.00\n",
      "421\n",
      "\n",
      "Epoch: 451\n",
      "Average train loss: 1.0424377381801606\n",
      "Test Accuracy: 72.37%\n",
      "epsilons: max 4.05,  mean 4.05, std 0.00\n",
      "451\n",
      "\n",
      "Epoch: 481\n",
      "Average train loss: 1.3688901513814926\n",
      "Test Accuracy: 72.23%\n",
      "epsilons: max 4.18,  mean 4.18, std 0.00\n",
      "481\n",
      "\n",
      "Epoch: 511\n",
      "Average train loss: 1.0848933432251215\n",
      "Test Accuracy: 72.37%\n",
      "epsilons: max 4.30,  mean 4.30, std 0.00\n",
      "511\n",
      "\n",
      "Epoch: 541\n",
      "Average train loss: 1.1458630129694938\n",
      "Test Accuracy: 73.32%\n",
      "epsilons: max 4.42,  mean 4.42, std 0.00\n",
      "541\n",
      "\n",
      "Epoch: 571\n",
      "Average train loss: 1.7325020730495453\n",
      "Test Accuracy: 72.37%\n",
      "epsilons: max 4.53,  mean 4.53, std 0.00\n",
      "571\n",
      "\n",
      "Epoch: 601\n",
      "Average train loss: 1.6278906852006911\n",
      "Test Accuracy: 72.37%\n",
      "epsilons: max 4.65,  mean 4.65, std 0.00\n",
      "601\n",
      "\n",
      "Epoch: 631\n",
      "Average train loss: 2.0078950464725493\n",
      "Test Accuracy: 72.23%\n",
      "epsilons: max 4.76,  mean 4.76, std 0.00\n",
      "631\n",
      "\n",
      "Epoch: 661\n",
      "Average train loss: 0.7366442933678627\n",
      "Test Accuracy: 72.50%\n",
      "epsilons: max 4.87,  mean 4.87, std 0.00\n",
      "661\n",
      "\n",
      "Epoch: 691\n",
      "Average train loss: 1.0183323707431555\n",
      "Test Accuracy: 72.50%\n",
      "epsilons: max 4.98,  mean 4.98, std 0.00\n",
      "691\n",
      "\n",
      "Epoch: 721\n",
      "Average train loss: 1.279178535938263\n",
      "Test Accuracy: 74.28%\n",
      "epsilons: max 5.08,  mean 5.08, std 0.00\n",
      "721\n",
      "\n",
      "Epoch: 751\n",
      "Average train loss: 1.302110480517149\n",
      "Test Accuracy: 72.78%\n",
      "epsilons: max 5.19,  mean 5.19, std 0.00\n",
      "751\n",
      "\n",
      "Epoch: 781\n",
      "Average train loss: 1.071476799249649\n",
      "Test Accuracy: 74.83%\n",
      "epsilons: max 5.29,  mean 5.29, std 0.00\n",
      "781\n",
      "\n",
      "Epoch: 811\n",
      "Average train loss: 1.080070748925209\n",
      "Test Accuracy: 74.69%\n",
      "epsilons: max 5.39,  mean 5.39, std 0.00\n",
      "811\n",
      "\n",
      "Epoch: 841\n",
      "Average train loss: 1.5498501032590866\n",
      "Test Accuracy: 75.79%\n",
      "epsilons: max 5.49,  mean 5.49, std 0.00\n",
      "841\n",
      "\n",
      "Epoch: 871\n",
      "Average train loss: 1.3900961086153985\n",
      "Test Accuracy: 76.06%\n",
      "epsilons: max 5.58,  mean 5.58, std 0.00\n",
      "871\n",
      "\n",
      "Epoch: 901\n",
      "Average train loss: 1.2506985783576965\n",
      "Test Accuracy: 75.24%\n",
      "epsilons: max 5.68,  mean 5.68, std 0.00\n",
      "901\n",
      "\n",
      "Epoch: 931\n",
      "Average train loss: 1.1775983149302192\n",
      "Test Accuracy: 75.51%\n",
      "epsilons: max 5.78,  mean 5.78, std 0.00\n",
      "931\n",
      "\n",
      "Epoch: 961\n",
      "Average train loss: 1.0888885051012038\n",
      "Test Accuracy: 74.28%\n",
      "epsilons: max 5.87,  mean 5.87, std 0.00\n",
      "961\n",
      "\n",
      "Epoch: 991\n",
      "Average train loss: 1.0380151539941835\n",
      "Test Accuracy: 74.42%\n",
      "epsilons: max 5.96,  mean 5.96, std 0.00\n",
      "991\n",
      "\n",
      "Epoch: 1021\n",
      "Average train loss: 1.2836167381610721\n",
      "Test Accuracy: 73.46%\n",
      "epsilons: max 6.05,  mean 6.05, std 0.00\n",
      "1021\n",
      "\n",
      "Epoch: 1051\n",
      "Average train loss: 0.9815390914678573\n",
      "Test Accuracy: 74.56%\n",
      "epsilons: max 6.15,  mean 6.15, std 0.00\n",
      "1051\n",
      "\n",
      "Epoch: 1081\n",
      "Average train loss: 1.3131526917219163\n",
      "Test Accuracy: 75.10%\n",
      "epsilons: max 6.24,  mean 6.24, std 0.00\n",
      "1081\n",
      "\n",
      "Epoch: 1111\n",
      "Average train loss: 1.5430449649691582\n",
      "Test Accuracy: 74.56%\n",
      "epsilons: max 6.32,  mean 6.32, std 0.00\n",
      "1111\n",
      "\n",
      "Epoch: 1141\n",
      "Average train loss: 1.9558857142925263\n",
      "Test Accuracy: 74.28%\n",
      "epsilons: max 6.41,  mean 6.41, std 0.00\n",
      "1141\n",
      "\n",
      "Epoch: 1171\n",
      "Average train loss: 1.6127178490161895\n",
      "Test Accuracy: 74.42%\n",
      "epsilons: max 6.50,  mean 6.50, std 0.00\n",
      "1171\n",
      "\n",
      "Epoch: 1201\n",
      "Average train loss: 1.1542355831246822\n",
      "Test Accuracy: 74.42%\n",
      "epsilons: max 6.58,  mean 6.58, std 0.00\n",
      "1201\n",
      "\n",
      "Epoch: 1231\n",
      "Average train loss: 1.3061110913753509\n",
      "Test Accuracy: 75.51%\n",
      "epsilons: max 6.67,  mean 6.67, std 0.00\n",
      "1231\n",
      "\n",
      "Epoch: 1261\n",
      "Average train loss: 1.6336829908192159\n",
      "Test Accuracy: 72.91%\n",
      "epsilons: max 6.75,  mean 6.75, std 0.00\n",
      "1261\n",
      "\n",
      "Epoch: 1291\n",
      "Average train loss: 1.4312793046236039\n",
      "Test Accuracy: 74.56%\n",
      "epsilons: max 6.84,  mean 6.84, std 0.00\n",
      "1291\n",
      "\n",
      "Epoch: 1321\n",
      "Average train loss: 1.666289968788624\n",
      "Test Accuracy: 75.38%\n",
      "epsilons: max 6.92,  mean 6.92, std 0.00\n",
      "1321\n",
      "\n",
      "Epoch: 1351\n",
      "Average train loss: 1.2944818764925003\n",
      "Test Accuracy: 73.73%\n",
      "epsilons: max 7.00,  mean 7.00, std 0.00\n",
      "1351\n",
      "\n",
      "Epoch: 1381\n",
      "Average train loss: 0.900818907545181\n",
      "Test Accuracy: 74.83%\n",
      "epsilons: max 7.09,  mean 7.09, std 0.00\n",
      "1381\n",
      "\n",
      "Epoch: 1411\n",
      "Average train loss: 0.8245966294780374\n",
      "Test Accuracy: 74.97%\n",
      "epsilons: max 7.17,  mean 7.17, std 0.00\n",
      "1411\n",
      "\n",
      "Epoch: 1441\n",
      "Average train loss: 2.0574686408042906\n",
      "Test Accuracy: 76.61%\n",
      "epsilons: max 7.25,  mean 7.25, std 0.00\n",
      "1441\n",
      "\n",
      "Epoch: 1471\n",
      "Average train loss: 1.0922214750258719\n",
      "Test Accuracy: 75.24%\n",
      "epsilons: max 7.33,  mean 7.33, std 0.00\n",
      "1471\n",
      "\n",
      "Epoch: 1501\n",
      "Average train loss: 0.7483208723308052\n",
      "Test Accuracy: 74.97%\n",
      "epsilons: max 7.41,  mean 7.41, std 0.00\n",
      "1501\n",
      "\n",
      "Epoch: 1531\n",
      "Average train loss: 1.0275813878513873\n",
      "Test Accuracy: 75.10%\n",
      "epsilons: max 7.48,  mean 7.48, std 0.00\n",
      "1531\n",
      "\n",
      "Epoch: 1561\n",
      "Average train loss: 1.6270009523257614\n",
      "Test Accuracy: 73.60%\n",
      "epsilons: max 7.56,  mean 7.56, std 0.00\n",
      "1561\n",
      "\n",
      "Epoch: 1591\n",
      "Average train loss: 1.2435616642236709\n",
      "Test Accuracy: 77.15%\n",
      "epsilons: max 7.64,  mean 7.64, std 0.00\n",
      "1591\n",
      "\n",
      "Epoch: 1621\n",
      "Average train loss: 0.9002696812152863\n",
      "Test Accuracy: 75.92%\n",
      "epsilons: max 7.71,  mean 7.71, std 0.00\n",
      "1621\n",
      "\n",
      "Epoch: 1651\n",
      "Average train loss: 1.2405086755752563\n",
      "Test Accuracy: 76.33%\n",
      "epsilons: max 7.79,  mean 7.79, std 0.00\n",
      "1651\n",
      "\n",
      "Epoch: 1681\n",
      "Average train loss: 0.8414239211706445\n",
      "Test Accuracy: 76.47%\n",
      "epsilons: max 7.87,  mean 7.87, std 0.00\n",
      "1681\n",
      "\n",
      "Epoch: 1711\n",
      "Average train loss: 1.1990172922611237\n",
      "Test Accuracy: 75.51%\n",
      "epsilons: max 7.94,  mean 7.94, std 0.00\n",
      "1711\n",
      "\n",
      "Epoch: 1741\n",
      "Average train loss: 1.5463334143161773\n",
      "Test Accuracy: 76.33%\n",
      "epsilons: max 8.02,  mean 8.02, std 0.00\n",
      "1741\n",
      "\n",
      "Epoch: 1771\n",
      "Average train loss: 1.0035676054656506\n",
      "Test Accuracy: 74.15%\n",
      "epsilons: max 8.09,  mean 8.09, std 0.00\n",
      "1771\n",
      "\n",
      "Epoch: 1801\n",
      "Average train loss: 0.8966000992222689\n",
      "Test Accuracy: 74.83%\n",
      "epsilons: max 8.17,  mean 8.17, std 0.00\n",
      "1801\n",
      "\n",
      "Epoch: 1831\n",
      "Average train loss: 1.7774979382753373\n",
      "Test Accuracy: 75.38%\n",
      "epsilons: max 8.24,  mean 8.24, std 0.00\n",
      "1831\n",
      "\n",
      "Epoch: 1861\n",
      "Average train loss: 1.3274790825322271\n",
      "Test Accuracy: 76.06%\n",
      "epsilons: max 8.31,  mean 8.31, std 0.00\n",
      "1861\n",
      "\n",
      "Epoch: 1891\n",
      "Average train loss: 1.4768219739198685\n",
      "Test Accuracy: 75.10%\n",
      "epsilons: max 8.38,  mean 8.38, std 0.00\n",
      "1891\n",
      "\n",
      "Epoch: 1921\n",
      "Average train loss: 1.2562436305941447\n",
      "Test Accuracy: 75.79%\n",
      "epsilons: max 8.45,  mean 8.45, std 0.00\n",
      "1921\n",
      "\n",
      "Epoch: 1951\n",
      "Average train loss: 1.079261130327359\n",
      "Test Accuracy: 75.92%\n",
      "epsilons: max 8.53,  mean 8.53, std 0.00\n",
      "1951\n",
      "\n",
      "Epoch: 1981\n",
      "Average train loss: 1.0335385203361511\n",
      "Test Accuracy: 75.65%\n",
      "epsilons: max 8.60,  mean 8.60, std 0.00\n",
      "1981\n",
      "\n",
      "Epoch: 2011\n",
      "Average train loss: 1.5446640759706498\n",
      "Test Accuracy: 73.05%\n",
      "epsilons: max 8.67,  mean 8.67, std 0.00\n",
      "2011\n",
      "\n",
      "Epoch: 2041\n",
      "Average train loss: 0.9841405741128255\n",
      "Test Accuracy: 74.28%\n",
      "epsilons: max 8.74,  mean 8.74, std 0.00\n",
      "2041\n",
      "\n",
      "Epoch: 2071\n",
      "Average train loss: 1.2356427431106567\n",
      "Test Accuracy: 74.56%\n",
      "epsilons: max 8.81,  mean 8.81, std 0.00\n",
      "2071\n",
      "\n",
      "Epoch: 2101\n",
      "Average train loss: 1.3388590414077044\n",
      "Test Accuracy: 75.10%\n",
      "epsilons: max 8.88,  mean 8.88, std 0.00\n",
      "2101\n",
      "\n",
      "Epoch: 2131\n",
      "Average train loss: 1.4482566632330418\n",
      "Test Accuracy: 75.10%\n",
      "epsilons: max 8.95,  mean 8.95, std 0.00\n",
      "2131\n",
      "\n",
      "Epoch: 2161\n",
      "Average train loss: 1.6120183706283568\n",
      "Test Accuracy: 74.15%\n",
      "epsilons: max 9.02,  mean 9.02, std 0.00\n",
      "2161\n",
      "\n",
      "Epoch: 2191\n",
      "Average train loss: 1.1626754401251673\n",
      "Test Accuracy: 73.60%\n",
      "epsilons: max 9.09,  mean 9.09, std 0.00\n",
      "2191\n",
      "\n",
      "Epoch: 2221\n",
      "Average train loss: 1.8099913954734803\n",
      "Test Accuracy: 73.46%\n",
      "epsilons: max 9.16,  mean 9.16, std 0.00\n",
      "2221\n",
      "\n",
      "Epoch: 2251\n",
      "Average train loss: 1.2859208025038242\n",
      "Test Accuracy: 73.60%\n",
      "epsilons: max 9.22,  mean 9.22, std 0.00\n",
      "2251\n",
      "\n",
      "Epoch: 2281\n",
      "Average train loss: 0.7701970211230218\n",
      "Test Accuracy: 70.31%\n",
      "epsilons: max 9.29,  mean 9.29, std 0.00\n",
      "2281\n",
      "\n",
      "Epoch: 2311\n",
      "Average train loss: 0.919431272149086\n",
      "Test Accuracy: 74.56%\n",
      "epsilons: max 9.36,  mean 9.36, std 0.00\n",
      "2311\n",
      "\n",
      "Epoch: 2341\n",
      "Average train loss: 1.4552948271142667\n",
      "Test Accuracy: 74.15%\n",
      "epsilons: max 9.42,  mean 9.42, std 0.00\n",
      "2341\n",
      "\n",
      "Epoch: 2371\n",
      "Average train loss: 0.9229130781255662\n",
      "Test Accuracy: 73.46%\n",
      "epsilons: max 9.49,  mean 9.49, std 0.00\n",
      "2371\n",
      "\n",
      "Epoch: 2401\n",
      "Average train loss: 1.0950526580214501\n",
      "Test Accuracy: 74.69%\n",
      "epsilons: max 9.56,  mean 9.56, std 0.00\n",
      "2401\n",
      "\n",
      "Epoch: 2431\n",
      "Average train loss: 0.8105157427489758\n",
      "Test Accuracy: 75.38%\n",
      "epsilons: max 9.63,  mean 9.63, std 0.00\n",
      "2431\n",
      "\n",
      "Epoch: 2461\n",
      "Average train loss: 1.7440265722572803\n",
      "Test Accuracy: 74.56%\n",
      "epsilons: max 9.69,  mean 9.69, std 0.00\n",
      "2461\n",
      "\n",
      "Epoch: 2491\n",
      "Average train loss: 1.6058862179517746\n",
      "Test Accuracy: 74.56%\n",
      "epsilons: max 9.76,  mean 9.76, std 0.00\n",
      "2491\n",
      "\n",
      "Epoch: 2521\n",
      "Average train loss: 1.1378908962011338\n",
      "Test Accuracy: 74.69%\n",
      "epsilons: max 9.82,  mean 9.82, std 0.00\n",
      "2521\n",
      "\n",
      "Epoch: 2551\n",
      "Average train loss: 2.3872986257076265\n",
      "Test Accuracy: 73.60%\n",
      "epsilons: max 9.89,  mean 9.89, std 0.00\n",
      "2551\n",
      "\n",
      "Epoch: 2581\n",
      "Average train loss: 0.7883930602110922\n",
      "Test Accuracy: 75.10%\n",
      "epsilons: max 9.95,  mean 9.95, std 0.00\n",
      "2581\n",
      "\n",
      "Epoch: 2611\n",
      "Average train loss: 1.276942177861929\n",
      "Test Accuracy: 74.28%\n",
      "epsilons: max 10.01,  mean 10.01, std 0.00\n",
      "2611\n",
      "\n",
      "Epoch: 2641\n",
      "Average train loss: 1.370180958509445\n",
      "Test Accuracy: 73.87%\n",
      "epsilons: max 10.08,  mean 10.08, std 0.00\n",
      "2641\n",
      "\n",
      "Epoch: 2671\n",
      "Average train loss: 1.2821424097754062\n",
      "Test Accuracy: 73.87%\n",
      "epsilons: max 10.14,  mean 10.14, std 0.00\n",
      "2671\n",
      "\n",
      "Epoch: 2701\n",
      "Average train loss: 1.440989726781845\n",
      "Test Accuracy: 73.19%\n",
      "epsilons: max 10.21,  mean 10.21, std 0.00\n",
      "2701\n",
      "\n",
      "Epoch: 2731\n",
      "Average train loss: 1.5192287415266037\n",
      "Test Accuracy: 73.46%\n",
      "epsilons: max 10.27,  mean 10.27, std 0.00\n",
      "2731\n",
      "\n",
      "Epoch: 2761\n",
      "Average train loss: 0.9208763502259899\n",
      "Test Accuracy: 73.60%\n",
      "epsilons: max 10.33,  mean 10.33, std 0.00\n",
      "2761\n",
      "\n",
      "Epoch: 2791\n",
      "Average train loss: 1.2961582779884337\n",
      "Test Accuracy: 73.87%\n",
      "epsilons: max 10.40,  mean 10.40, std 0.00\n",
      "2791\n",
      "\n",
      "Epoch: 2821\n",
      "Average train loss: 0.8416908806033462\n",
      "Test Accuracy: 74.69%\n",
      "epsilons: max 10.46,  mean 10.46, std 0.00\n",
      "2821\n",
      "\n",
      "Epoch: 2851\n",
      "Average train loss: 1.1525595715735109\n",
      "Test Accuracy: 74.97%\n",
      "epsilons: max 10.52,  mean 10.52, std 0.00\n",
      "2851\n",
      "\n",
      "Epoch: 2881\n",
      "Average train loss: 0.9540297769010067\n",
      "Test Accuracy: 74.56%\n",
      "epsilons: max 10.58,  mean 10.58, std 0.00\n",
      "2881\n",
      "\n",
      "Epoch: 2911\n",
      "Average train loss: 1.1379423439502716\n",
      "Test Accuracy: 74.01%\n",
      "epsilons: max 10.65,  mean 10.65, std 0.00\n",
      "2911\n",
      "\n",
      "Epoch: 2941\n",
      "Average train loss: 1.0055850505828858\n",
      "Test Accuracy: 74.97%\n",
      "epsilons: max 10.71,  mean 10.71, std 0.00\n",
      "2941\n",
      "\n",
      "Epoch: 2971\n",
      "Average train loss: 1.5548095494508742\n",
      "Test Accuracy: 75.10%\n",
      "epsilons: max 10.77,  mean 10.77, std 0.00\n",
      "2971\n",
      "\n",
      "Epoch: 3001\n",
      "Average train loss: 1.4640826493501664\n",
      "Test Accuracy: 74.15%\n",
      "epsilons: max 10.83,  mean 10.83, std 0.00\n",
      "3001\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "## etc.\n",
    "parser.add_argument('--sub_dataset_size', type=int, default=-1, help='To reduce original data to a smaller \\\n",
    "                    sized dataset. For experimental purposes.')\n",
    "\n",
    "# federated arguments (Notation for the arguments followed from paper)\n",
    "parser.add_argument('--epochs', type=int, default=3001,\n",
    "                    help=\"number of rounds of training\")\n",
    "\n",
    "parser.add_argument('--num_users', type=int, default=10,\n",
    "                    help=\"number of users: K\")\n",
    "\n",
    "parser.add_argument('--frac', type=float, default=1.,\n",
    "                    help='the fraction of clients: C')\n",
    "\n",
    "parser.add_argument('--local_ep', type=int, default=1,\n",
    "                    help=\"the number of local epochs: E\")\n",
    "\n",
    "parser.add_argument('--local_bs', type=int, default=1,\n",
    "                    help=\"local batch size: B\")\n",
    "\n",
    "parser.add_argument('--virtual_batch_size', type=int, default=1, \n",
    "                    help='DP VIRTUAL_BATCH_SIZE')\n",
    "\n",
    "## Optimizer\n",
    "parser.add_argument('--optimizer', type=str, default='sgd', help=\"type \\\n",
    "                    of optimizer\")\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=.002,\n",
    "                    help='learning rate')\n",
    "\n",
    "parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                    help='SGD momentum (default: 0.0)')\n",
    "\n",
    "\n",
    "# model arguments\n",
    "parser.add_argument('--model', type=str, default='cnn', help='model name')\n",
    "\n",
    "parser.add_argument('--activation', type=str, default=\"tanh\",\n",
    "                    help='SGD momentum (default: 0.0)')\n",
    "\n",
    "# other arguments\n",
    "parser.add_argument('--dataset', type=str, default='dr', help=\"name \\\n",
    "                    of dataset\")\n",
    "\n",
    "parser.add_argument('--gpu', default=\"cuda:0\", help=\"To use cuda, set \\\n",
    "                    to a specific GPU ID. Default set to use CPU.\")\n",
    "\n",
    "parser.add_argument('--iid', type=int, default=1,\n",
    "                    help='Default set to IID. Set to 0 for non-IID.')\n",
    "\n",
    "parser.add_argument('--unequal', type=int, default=0,\n",
    "                    help='whether to use unequal data splits for  \\\n",
    "                    non-i.i.d setting (use 0 for equal splits)')\n",
    "                    \n",
    "parser.add_argument('--local_test_split', type=float, default=0., help='DP DELTA')                    \n",
    "parser.add_argument('--dr_from_np', type=float, default=1, help='for diabetic_retinopathy dataset')                    \n",
    "\n",
    "\n",
    "## DP arguments\n",
    "parser.add_argument('--withDP', type=int, default=1, help='WithDP')\n",
    "parser.add_argument('--max_grad_norm', type=float, default= 2., help='DP MAX_GRAD_NORM')\n",
    "parser.add_argument('--noise_multiplier', type=float, default=1.15, help='DP NOISE_MULTIPLIER')\n",
    "parser.add_argument('--delta', type=float, default=1e-4, help='DP DELTA')\n",
    "parser.add_argument('--sampling_prob', type=int, default=0.03425 , help='sampling_prob') \n",
    "\n",
    "\n",
    "parser.add_argument('--exp_name', type=str,\n",
    "                    default=\"test_fscdp\", help=\"The name of current experiment for logging.\")\n",
    "\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "\n",
    "main(args)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMVoD33K4k5muwkGeJFwjqT",
   "collapsed_sections": [],
   "name": "JNotebook_running_FSCDP_on_Colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
